#!/usr/bin/python3

import sys
import os
import argparse
import textwrap
import json
import subprocess
import re
import time
import urllib.request
import urllib.error
from functools import partial
from datetime import datetime
from blessed import Terminal

# Configuration
PROM_URL = os.getenv("GPUDASH_PROM_URL", "http://localhost:9200/prom/neumann")

# Utilization thresholds (can be overridden via environment variables)
UTIL_THRESHOLD_LOW = int(os.getenv("GPUDASH_UTIL_THRESHOLD_LOW", "25"))
UTIL_THRESHOLD_MED = int(os.getenv("GPUDASH_UTIL_THRESHOLD_MED", "50"))
UTIL_THRESHOLD_HIGH = int(os.getenv("GPUDASH_UTIL_THRESHOLD_HIGH", "75"))


def query_prometheus_range(metric_name, start_time, end_time, step="5m", retries=3):
    """Query Prometheus for a metric over a time range with retry logic."""
    url = f"{PROM_URL}/api/v1/query_range?query={metric_name}&start={start_time}&end={end_time}&step={step}"

    for attempt in range(retries):
        try:
            with urllib.request.urlopen(url, timeout=30) as response:
                data = response.read()
                return json.loads(data)
        except (urllib.error.URLError, urllib.error.HTTPError, OSError) as e:
            if attempt < retries - 1:
                wait_time = 2**attempt  # Exponential backoff: 1s, 2s, 4s
                print(f"Warning: Prometheus query failed (attempt {attempt + 1}/{retries}), retrying in {wait_time}s...", file=sys.stderr)
                time.sleep(wait_time)
            else:
                print(f"Error querying Prometheus for {metric_name}: {e}")
                return {"status": "error", "data": {"result": []}}


def generate_uid2user_mapping():
    """Generate uid to username mapping dictionary using getent passwd."""
    try:
        output = subprocess.run(["getent", "passwd"], capture_output=True, timeout=10, check=True)
        lines = output.stdout.decode("utf-8").strip().split("\n")
        uid2user = {}
        for line in lines:
            parts = line.split(":")
            if len(parts) >= 3:
                uid = parts[2]
                username = parts[0]
                uid2user[uid] = username
        return uid2user
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
        print(f"Warning: Error generating uid2user mapping: {e}", file=sys.stderr)
        return {}


def process_range_data(metric_data, uid2user=None):
    """
    Process Prometheus range query data and organize by timestamp.
    Returns:
        - dict with structure {timestamp: {(node, gpu_index): value}}
        - dict with structure {node: gpu_count}
    """
    result = {}
    nodes_gpus = {}

    if metric_data.get("status") != "success":
        return result, nodes_gpus

    for series in metric_data.get("data", {}).get("result", []):
        hostname = series["metric"].get("instance", "")
        # Handle case where instance might have port
        if ":" in hostname:
            hostname = hostname.split(":")[0]

        if not hostname:
            continue

        gpu_index = series["metric"]["minor_number"]

        # Track nodes and GPU indices for node discovery
        if hostname not in nodes_gpus:
            nodes_gpus[hostname] = set()
        if gpu_index is not None:
            nodes_gpus[hostname].add(int(gpu_index))

        values = series.get("values", [])

        for timestamp, value in values:
            ts = int(timestamp)
            if ts not in result:
                result[ts] = {}

            # Convert UID to username if this is UID data and mapping is available
            if uid2user and value in uid2user:
                value = uid2user[value]
            elif not uid2user:
                # For utilization data, round float values to integers
                try:
                    value = str(int(round(float(value))))
                except (ValueError, TypeError):
                    value = "N/A"

            result[ts][(hostname, gpu_index)] = value

    # Convert sets to GPU counts (max GPU index + 1)
    gpu_counts = {}
    for hostname, gpu_indices in nodes_gpus.items():
        if gpu_indices:
            gpu_counts[hostname] = max(gpu_indices) + 1

    return result, gpu_counts


def center(maxlen, txt):
    """Add white space with text in the center."""
    n = len(txt)
    if n > maxlen:
        txt = txt[:maxlen]
    pre = " " * int(0.5 * (maxlen - n))
    post = " " * (maxlen - n - len(pre))
    return pre + txt + post


def leftpad(txt, maxnode):
    """Left pad text to maxnode length."""
    n = len(txt)
    return " " * (maxnode - n) + txt


def colorize(user, util, term, padding):
    """Colorize the dashboard cell based on user and utilization."""
    if user == "OFFLINE":
        return padding(user)

    if user == "NODE LOST":
        return term.on_gray + term.black + padding(user) + term.normal

    text = f"{user}:{util}"
    if text == "root:0":
        return term.on_gray + term.black + padding("IDLE") + term.normal
    if text == "root:N/A":
        return term.on_gray + term.black + padding("NO INFO") + term.normal

    white = term.color_rgb(255, 255, 255)

    # Parse utilization value
    try:
        util_int = int(round(float(util)))
    except (ValueError, TypeError):
        util_int = -1

    if util_int == -1 or util == "N/A":
        return term.on_gray + term.black + padding(text) + term.normal
    elif util_int == 0:
        return term.on_black + white + padding(text) + term.normal
    elif util_int < UTIL_THRESHOLD_LOW:
        return term.on_blue + white + padding(text) + term.normal
    elif util_int < UTIL_THRESHOLD_MED:
        return term.on_cyan + term.black + padding(text) + term.normal
    elif util_int < UTIL_THRESHOLD_HIGH:
        return term.on_color_rgb(255, 165, 0) + term.black + padding(text) + term.normal
    elif util_int <= 100:
        return term.on_color_rgb(255, 0, 0) + white + padding(text) + term.normal
    else:
        return padding(text)


def construct_dashboard(nodelist, gpus_per_node, stats, times, maxnode, term, args):
    """Construct the GPU utilization dashboard."""
    s = "\n"
    day_date = str(datetime.now().strftime("%a %b %-d"))
    text = f"GPU UTILIZATION ({day_date})"
    total_width = args.chars_per_cell * len(times) + maxnode + 3
    s += center(total_width, text)
    s += "\n\n"

    # Time labels at top of dashboard
    s += " " * (maxnode + 3)
    padding = partial(center, args.chars_per_cell)
    for t in times:
        s += padding(t)
    s += "\n"

    # Main dashboard
    founduser_all_nodes = False
    for node in nodelist:
        rows = ""
        founduser_per_node = False
        offline = 0
        for gpu_index in [str(i) for i in range(gpus_per_node[node])]:
            if gpu_index == "0":
                rows += leftpad(node, maxnode)
            else:
                rows += " " * maxnode
            rows += " " + gpu_index + " "

            for j, t in enumerate(times):
                if (t, node, gpu_index) in stats:
                    username, util = stats[(t, node, gpu_index)]
                else:
                    username, util = ("NODE LOST", 0)

                if args.netid == username:
                    founduser_per_node = True
                    founduser_all_nodes = True
                if j == len(times) - 1 and username == "OFFLINE":
                    offline += 1
                rows += colorize(username, util, term, padding)
            rows += "\n"

        if (args.netid == "-1" or founduser_per_node) and offline < gpus_per_node[node]:
            s += rows

    # Time labels at bottom of dashboard
    if args.netid == "-1":
        s += " " * (maxnode + 3)
        for t in times:
            s += padding(t)
        s += "\n"

    # No jobs found for single user
    if args.netid != "-1" and not founduser_all_nodes:
        s += center(total_width, f"No GPU jobs found for {args.netid}\n")

    return s, founduser_all_nodes


def legend(term, maxnode):
    """Generate the legend for the dashboard."""
    offset = " " * (maxnode + 3)
    gu = "   " + term.normal + " GPU utilization is "
    s = ""
    s += offset + term.on_black + gu + "0%\n"
    s += offset + term.on_blue + gu + f"0-{UTIL_THRESHOLD_LOW}%\n"
    s += offset + term.on_cyan + gu + f"{UTIL_THRESHOLD_LOW}-{UTIL_THRESHOLD_MED}%\n"
    s += offset + term.on_color_rgb(255, 165, 0) + gu + f"{UTIL_THRESHOLD_MED}-{UTIL_THRESHOLD_HIGH}%\n"
    s += offset + term.on_color_rgb(255, 0, 0) + gu + f"{UTIL_THRESHOLD_HIGH}-100%\n"
    return s


def parse_time(time_str):
    """Parse time string like '1d', '1h', '30m' to seconds."""
    match = re.match(r"(\d+)([dhm])", time_str.lower())
    if not match:
        print(f"Invalid time format: {time_str}. Use format like '1d', '1h' or '30m'")
        sys.exit(1)
    value, unit = match.groups()
    value = int(value)
    if unit == "d":
        return value * 86400
    elif unit == "h":
        return value * 3600
    elif unit == "m":
        return value * 60
    return value


if __name__ == "__main__":
    psr = argparse.ArgumentParser(
        description="GPU utilization dashboard",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=textwrap.dedent("""
    Utilization is the percentage of time during a sampling window (< 1 second) that
    a kernel was running on the GPU. The format of each entry in the dashboard is
    username:utilization (e.g., aturing:90). Utilization varies between 0 and 100%.

    Examples:

      Show dashboard for all users (last hour):
        $ gpudash

      Show dashboard for last 2 hours with 10-minute intervals:
        $ gpudash --period 2h --interval 10m

      Show dashboard for the current user:
        $ gpudash --me

      Show dashboard for the user aturing:
        $ gpudash -u aturing

      Show dashboard for all users without displaying legend:
        $ gpudash -n

      Output data in JSON format for programmatic use:
        $ gpudash --json | jq '.summary'
    """),
    )
    psr.add_argument("-u", type=str, action="store", dest="netid", default="-1", help="create dashboard for a single user")
    psr.add_argument("-n", "--no-legend", action="store_true", help="flag to hide the legend")
    psr.add_argument("--me", action="store_true", help="create dashboard for current user")
    psr.add_argument("-c", "--chars-per-cell", type=int, default=15, help="number of characters per cell in the dashboard. Default: 15")
    psr.add_argument("-p", "--period", type=str, default="1h", help="time period to show (e.g., 1h, 2h, 30m). Default: 1h")
    psr.add_argument("-i", "--interval", type=str, default="10m", help="sampling interval (e.g., 5m, 10m, 15m). Default: 10m")
    psr.add_argument("--json", action="store_true", help="output data in JSON format instead of dashboard")
    args = psr.parse_args()

    show_legend = not args.no_legend
    if args.me:
        args.netid = os.getenv("USER")
        if not args.netid:
            args.netid = "-1"

    period_seconds = parse_time(args.period)
    interval_seconds = parse_time(args.interval)

    # Calculate time range
    end_time = int(time.time())
    start_time = end_time - period_seconds

    # Generate uid to username mapping
    uid2user = generate_uid2user_mapping()

    # Query Prometheus for GPU metrics over the time range
    step = f"{interval_seconds}s"
    duty_cycle_data = query_prometheus_range("nvidia_gpu_duty_cycle", start_time, end_time, step)
    uid_data = query_prometheus_range("nvidia_gpu_jobUid", start_time, end_time, step)

    # Process the data and extract node information
    util_by_time, gpus_per_node = process_range_data(duty_cycle_data)
    uid_by_time, _ = process_range_data(uid_data, uid2user)

    # Check if we found any nodes
    if not gpus_per_node:
        print("No GPU nodes found from Prometheus. Exiting ...")
        sys.exit(0)

    nodelist = sorted(list(gpus_per_node.keys()))
    maxnode = max(map(len, nodelist)) if nodelist else 0

    # Get all timestamps and sort them
    all_timestamps = sorted(set(util_by_time.keys() | uid_by_time.keys()))

    if not all_timestamps:
        print("No data available for the specified time range.")
        sys.exit(0)

    # Build stats dictionary
    stats = {}
    times = []

    for ts in all_timestamps:
        twelve_hour = datetime.fromtimestamp(ts).strftime("%-I:%M %p")
        times.append(twelve_hour)

        # Initialize all GPUs for this timestamp
        for node in nodelist:
            for gpu_index in range(gpus_per_node[node]):
                gpu_index_str = str(gpu_index)

                # Get values from each metric
                util = util_by_time.get(ts, {}).get((node, gpu_index_str), "N/A")
                username = uid_by_time.get(ts, {}).get((node, gpu_index_str), "OFFLINE")

                # Handle the case where we have util=0 but no user info
                if username == "OFFLINE" and util == "0":
                    username = "root"

                stats[(twelve_hour, node, gpu_index_str)] = (username, util)

    if args.json:
      # Output in JSON format if requested
        json_output = {
            "timestamp": datetime.now().isoformat(),
            "period": args.period,
            "interval": args.interval,
            "nodes": {},
            "summary": {
                "total_gpus": sum(gpus_per_node.values()),
                "total_nodes": len(nodelist),
                "active_users": len(set(u for (u, _) in stats.values() if u not in ["root", "OFFLINE", "NODE LOST"])),
            },
        }

        for node in nodelist:
            json_output["nodes"][node] = {"gpu_count": gpus_per_node[node], "gpus": {}}
            for gpu_idx in range(gpus_per_node[node]):
                gpu_idx_str = str(gpu_idx)
                json_output["nodes"][node]["gpus"][gpu_idx_str] = []
                for time_label in times:
                    if (time_label, node, gpu_idx_str) in stats:
                        username, util = stats[(time_label, node, gpu_idx_str)]
                        json_output["nodes"][node]["gpus"][gpu_idx_str].append({"time": time_label, "user": username, "utilization": util})

        print(json.dumps(json_output, indent=2))
    else:
        # Construct and print dashboard
        term = Terminal()
        dashboard, founduser_all_nodes = construct_dashboard(nodelist, gpus_per_node, stats, times, maxnode, term, args)
        print(dashboard)

        if args.netid == "-1":
            if show_legend:
                print(legend(term, maxnode))
        else:
            if show_legend and founduser_all_nodes:
                print(legend(term, maxnode))
